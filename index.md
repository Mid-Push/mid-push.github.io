---
layout: homepage
---



Hi! I’m a PhD student at [Carnegie Mellon University](https://www.cmu.edu/), advised by [Prof. Kun Zhang](https://www.andrew.cmu.edu/user/kunz1/).  


## Research Highlights

My long-term research goal is to develop generative AI systems that go beyond producing realistic multi-modal data to capturing the underlying structure of the world. By embedding causal principles into machine learning and computer vision, I aim to make generative models not only powerful, but also controllable, interpretable, trustworthy, and capable of systematic generalization.

In my recent work, I have explored this vision through several directions:

- **Video generation**: developing models that synthesize realistic and temporally consistent videos [<a href="https://arxiv.org/pdf/2502.02690">arXiv ’25</a>].  
- **Text-to-image generation**: advancing controllable and scalable text-driven image synthesis [<a href="https://openreview.net/pdf?id=hUHRTaTfvZ">ICML ’25</a>, <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_SmartCLIP_Modular_Vision-language_Alignment_with_Identification_Guarantees_CVPR_2025_paper.pdf">CVPR ’25</a>, <a href="https://arxiv.org/pdf/2312.03771">arXiv '23</a>, <a href="https://arxiv.org/pdf/2212.05034.pdf">CVPR ’23</a>].  
- **Conditional image generation**: designing methods that flexibly adapt to conditioning signals [<a href="https://arxiv.org/pdf/2212.05034.pdf">CVPR ’23</a>, <a href="https://openreview.net/pdf?id=U2g8OGONA_V">ICLR ’23</a>, <a href="https://openreview.net/pdf?id=RNZ8JOmNaV4">NeurIPS ’22</a>, <a href="https://arxiv.org/pdf/2306.12511.pdf">NeuIPS’23</a>, <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Maximum_Spatial_Perturbation_Consistency_for_Unpaired_Image-to-Image_Translation_CVPR_2022_paper.pdf">CVPR ’22</a>, <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Xie_Unaligned_Image-to-Image_Translation_by_Learning_to_Reweight_ICCV_2021_paper.pdf">ICCV ’21</a>].  
- **Causal representation learning**: extracting disentangled and structured latent factors from different modalities to enable systematic generalization [<a href="https://openreview.net/pdf?id=cW9Ttnm1aC">ICML ’25</a>, <a href="https://arxiv.org/pdf/2306.12511.pdf">ICLR ’25</a>, <a href="https://openreview.net/attachment?id=S8lfepB2fz&name=pdf">AISTATS ’25</a>, <a href="https://arxiv.org/pdf/2402.05052">ICML ’24</a>, <a href="https://proceedings.mlr.press/v162/kong22a/kong22a.pdf">ICML ’22</a>].  
- **Counterfactual inference**: building frameworks that empower models to answer “what if” questions and reason about interventions [<a href="https://arxiv.org/pdf/2306.05751">arXiv ’24</a>].








## News
- **[Aug. 2025]** I will be serving as an Area Chair for ICLR2026, thanks for the invitation!
- **[June. 2025]** I'm attending CVPR2025, see you in Nashville!
- **[May. 2025]** Two papers are accepted into ICML2025!
- **[April. 2025]** One paper is accepted as CVPR2025 Highlight!
- **[May. 2023]** I'm thrilled to share that my work at Adobe <a href="https://arxiv.org/pdf/2212.05034.pdf" style="color:#71b07b;">SmartBrush (CVPR2023, Highlight)</a> is now alive in Adobe flagship products - <a href="https://www.adobe.com/products/photoshop/generative-fill.html?sdid=G4FRYPQC&mv=search%2Csearch&mv2=paidsearch&ef_id=CjwKCAjw67ajBhAVEiwA2g_jEPPTmpltXFA3YzZdxylZYn1SMlNg2BEZIb6dCQfEVtWYjc3eBUdEQxoCtqUQAvD_BwE%3AG%3As&s_kwcid=AL%213085%213%21522507805122%21e%21%21g%21%21adobe+photoshop%218021501881%2179642044381&gbraid=0AAAAADraYsIWtl1hYdDJvAWgxzgO2pHJE&gclid=CjwKCAjw67ajBhAVEiwA2g_jEPPTmpltXFA3YzZdxylZYn1SMlNg2BEZIb6dCQfEVtWYjc3eBUdEQxoCtqUQAvD_BwE" style="color:#71b07b;">Photoshop and Firefly</a>!
- **[Jan. 2023]** One paper <a href="https://openreview.net/pdf?id=U2g8OGONA_V" style="color:#71b07b;">i-stylegan</a> is accepted as ICLR2023 Spotlight! One of the first works to connect identifiability with multidomain image generation.

{% include_relative _includes/publications.md %}

{% include_relative _includes/services.md %}
