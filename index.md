---
layout: homepage
---

Hi! I'm a PhD student at <a href="https://www.cmu.edu/" style="color:#1E90FF;">Carnegie Mellon University</a>, advised by <a href="https://www.andrew.cmu.edu/user/kunz1/" style="color:#1E90FF;">Prof. Kun Zhang</a> and <a href="https://www.cmu.edu/dietrich/philosophy/people/faculty/spirtes.html" style="color:#1E90FF;">Prof. Peter Spirtes</a>.  
I have also been fortunate to intern at <a href="https://research.adobe.com/" style="color:#1E90FF;">Adobe Research</a> with <a href="https://sites.google.com/site/zhelin625/" style="color:#1E90FF;">Zhe Lin</a>, <a href="https://zzutk.github.io/" style="color:#1E90FF;">Zhifei Zhang</a>, and <a href="https://www.tobiashinz.com/" style="color:#1E90FF;">Tobias Hinz</a>, and at <a href="https://research.google/" style="color:#1E90FF;">Google</a> with <a href="https://sites.google.com/view/zhao-yang/" style="color:#1E90FF;">Yang Zhao</a>, <a href="https://xavierxiao.github.io/" style="color:#1E90FF;">Zhisheng Xiao</a>, and <a href="https://ckkelvinchan.github.io/" style="color:#1E90FF;">Kelvin C. K. Chan</a>.
My long-term research goal is to develop generative AI systems that go beyond producing realistic multimodal data to capturing the underlying structure of the world. By grounding machine learning and computer vision in principled representations of structure and dependencies, I aim to make generative models not only powerful, but also controllable, interpretable, trustworthy, and capable of systematic generalization.

---

## News
- **[Sep. 2025]** My work has been featured by <a href="https://www.cmu.edu/news/stories/archives/2025/september/peacocks-eating-ice-cream-cmu-philosophers-teaching-ai-to-ask-why" style="color:#1E90FF;">CMU News</a> and <a href="https://mbzuai.ac.ae/news/create-and-edit-images-like-a-smart-artist/" style="color:#1E90FF;">MBZUAI News</a>! 
- **[Aug. 2025]** I will be serving as an Area Chair for <a href="https://iclr.cc/" style="color:#1E90FF;">ICLR 2026</a> — thanks for the invitation!  
- **[May. 2025]** Two papers accepted into <a href="https://icml.cc/" style="color:#1E90FF;">ICML 2025</a>!  
- **[Apr. 2025]** One paper accepted as a <a href="https://cvpr.thecvf.com/" style="color:#1E90FF;">CVPR 2025 Highlight</a>!  
- **[2023]** My work at Adobe, <a href="https://arxiv.org/pdf/2212.05034.pdf" style="color:#1E90FF;">SmartBrush (CVPR 2023, Highlight)</a>, is now integrated into Adobe's flagship products — <a href="https://www.adobe.com/products/photoshop/generative-fill.html" style="color:#1E90FF;">Photoshop and Firefly</a>!  
- **[2023]** One paper, <a href="https://openreview.net/pdf?id=U2g8OGONA_V" style="color:#1E90FF;">i-StyleGAN</a>, accepted as an <a href="https://iclr.cc/" style="color:#1E90FF;">ICLR 2023 Spotlight</a>! One of the first works to connect identifiability with multidomain image generation.

---

## Publications  

{% include_relative _includes/publications.html %}  

## Services  

{% include_relative _includes/services.md %}  
